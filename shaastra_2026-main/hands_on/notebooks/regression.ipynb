{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for input 10: 30.000000000000007\n",
      "Coefficient (Slope/Beta): 7.939773296511684\n",
      "Intercept (Bias): 12.4\n",
      "R² Score: 1.0\n",
      "Mean Squared Error: 7.888609052210118e-31\n",
      "Mean Absolute Error: 5.329070518200751e-16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Prepare the Data\n",
    "X = np.array([[1], [3], [6], [9], [12]])\n",
    "y = np.array([2, 6, 12, 18, 24])   # y = 2x\n",
    "\n",
    "# Step 2: Standardize the features,why standardscaler?, because ridge regression is sensitive to the scale of the input features.meaning: it helps to improve the model performance and convergence.what standard scaler does on x data : it standardizes the features by removing the mean and scaling to unit variance.meaning: it transforms the data such that it has a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Create the Ridge Model\n",
    "ridge_model = Ridge(alpha=0)#alpha ante endhuku ante, regularization parameter ni set chesthundi, ridge regression lo. alpha value 0 set cheste, ridge regression ordinary least squares regression laga behave chesthundi, ante regularization apply avvadu.\n",
    "#loss = mse + alpha * summation w * w\n",
    "# Step 4: Train the model\n",
    "ridge_model.fit(X_scaled, y)\n",
    "\n",
    "# Step 5: Make prediction for new input\n",
    "input_value = np.array([[15]])\n",
    "input_value_scaled = scaler.transform(input_value)\n",
    "single_prediction = ridge_model.predict(input_value_scaled)\n",
    "\n",
    "print(f\"Prediction for input 10: {single_prediction[0]}\")\n",
    "\n",
    "# Step 6: Evaluate the model (IMPORTANT: use scaled X)\n",
    "y_pred = ridge_model.predict(X_scaled)\n",
    "\n",
    "print(f\"Coefficient (Slope/Beta): {ridge_model.coef_[0]}\")\n",
    "print(f\"Intercept (Bias): {ridge_model.intercept_}\")\n",
    "print(f\"R² Score: {r2_score(y, y_pred)}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y, y_pred)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1, 10) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m svr_model \u001b[38;5;241m=\u001b[39m SVR(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Step 3: Train on Scaled Data\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m svr_model\u001b[38;5;241m.\u001b[39mfit(X_scaled, y_scaled)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Step 4: Prediction\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Let's predict for input 5.5 (Middle of the wave)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m input_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m5.5\u001b[39m]])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/svm/_base.py:197\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    195\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    199\u001b[0m         X,\n\u001b[1;32m    200\u001b[0m         y,\n\u001b[1;32m    201\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    202\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    203\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    207\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    209\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    210\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    211\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1387\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1371\u001b[0m     X,\n\u001b[1;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[0;32m-> 1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1408\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1408\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1409\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[1;32m   1410\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:1485\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn, device)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1473\u001b[0m             (\n\u001b[1;32m   1474\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1480\u001b[0m         )\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(\n\u001b[1;32m   1482\u001b[0m         xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m   1483\u001b[0m     )\n\u001b[0;32m-> 1485\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1487\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1, 10) instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Prepare the Data\n",
    "X_raw = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "y_raw = np.array([3.0, 2.5, 4.2, 3.8, 5.5, 2.5, 4.0, 3.0, 4.5, 3.5])  # Non-linear relationship\n",
    "# Step 1: Create Curved Data (A Sine Wave pattern)\n",
    "# Input X: years of experience\n",
    "X_raw = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "# Output y: some curved relationship,based on salary\n",
    "y_raw = np.array([6,7,9,12,15,18,22,35,40,100])\n",
    "\n",
    "\n",
    "# --- CRITICAL STEP FOR SVR: SCALING ---\n",
    "# SVR fails if data is not scaled because it measures distances.\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "#difference b/w standard scaler and pipeline:telugu lo,ikkada standard scaler ni direct ga use chesthunnam data ni scale cheyadaniki. pipeline ante, multiple steps ni combine chesi oka single object laga treat cheyadam. pipeline lo scaling, model training anni steps include cheyachu. kani ikkada simple ga scaling matrame chesamu.\n",
    "#scaling ante: data ni oka specific range lo convert cheyadam, usually mean 0 and standard deviation 1 ki. idi important because SVR distance based algorithm, so data scale chesinappudu better performance istundi.\n",
    "\n",
    "# Scale X and reshape y to 2D for scaling, then back to 1D\n",
    "X_scaled = scaler_X.fit_transform(X_raw)\n",
    "y_scaled = scaler_y.fit_transform(y_raw.reshape(-1, 1)).flatten(),#flatten endhuku ante, y ni 1D array ga convert cheyadaniki use chestharu. SVR model ki 1D array format lo undali output data.,ikkada already ,1d lo undhi kahda malli flatten endhuku ante,: just to be safe ga flatten chesamu.\n",
    "\n",
    "\n",
    "# Step 2: Create the SVR Model\n",
    "# kernel='rbf': The \"magic\" for curves (Radial Basis Function). Not linear.\n",
    "#rbf ante enthi ante, radial basis function ane kernel type. idi non-linear relationships ni capture cheyadaniki use chestharu. SVR lo rbf kernel use cheste, model complex curves ni fit cheyagaladu.\n",
    "# C=10.0: How hard it tries to fit outside points (Regularization).\n",
    "# epsilon=0.1: The width of the \"Tube\" where errors are ignored.\n",
    "#entire meaning enti ante: ikkada SVR model create chesthunnam with radial basis function kernel, which is good for capturing non-linear relationships. C parameter set chesam to 10.0, which means model will try hard to fit the data points, and epsilon set to 0.1, which defines a margin of tolerance where no penalty is given for errors.,flatten mandatory ah ante, yes flatten is mandatory for y_scaled to ensure it is in the correct shape for SVR training.\n",
    "svr_model = SVR(kernel='rbf', C=10.0, epsilon=0.1)\n",
    "\n",
    "# Step 3: Train on Scaled Data\n",
    "svr_model.fit(X_scaled, y_scaled)\n",
    "\n",
    "# Step 4: Prediction\n",
    "# Let's predict for input 5.5 (Middle of the wave)\n",
    "input_val = np.array([[5.5]])\n",
    "\n",
    "# 4a. Scale the input\n",
    "input_scaled = scaler_X.transform(input_val)\n",
    "\n",
    "# 4b. Make prediction (Result is scaled)\n",
    "prediction_scaled = svr_model.predict(input_scaled)\n",
    "\n",
    "# 4c. Inverse Scale the output back to real world numbers\n",
    "prediction_real = scaler_y.inverse_transform([[prediction_scaled[0]]])\n",
    "\n",
    "print(\"--- SVR Results ---\")\n",
    "print(f\"Input Value: {input_val[0][0]}\")\n",
    "print(f\"Predicted Value (Real Scale): {prediction_real[0][0]:.2f}\")\n",
    "print(f\"Actual target nearby (Input 5 is 4.2, Input 6 is 2.5)\")\n",
    "sns.lineplot(x=X_raw.flatten(), y=y_raw, color='blue', label='Actual Data')\n",
    "plt.show()\n",
    "# The prediction should be between 4.2 and 2.5\n",
    "#explantion in telugu:ee visualisation meaning enti ante,\n",
    "#blue line actual data ni represent chesthundi, adi sine wave pattern follow chesthundi.inka prediction point (input 5.5 ki) adi expected value ni represent chesthundi, adi blue line mida undi, meaning adi actual data pattern ni follow chesthundi. so model correct ga predict chesindi ani artham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for input [6, 4]: 12.0\n",
      "Intercept (Bias): 0.0\n",
      "Coefficients (Weights): [2. 0.]\n",
      "r2_score: 1.0\n",
      "\n",
      "--- CRYSTAL CLEAR RESULTS ---\n",
      "Importance of Study Hours: 2.00\n",
      "Importance of Lucky Number: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1336: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:716: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Step 1: Prepare Data with 2 Features\n",
    "# Column 0: Study Hours (Important)\n",
    "# Column 1: Lucky Number (Useless/Garbage)\n",
    "X = np.array([\n",
    "    [1, 7], \n",
    "    [2, 3], \n",
    "    [3, 5], \n",
    "    [4, 2], \n",
    "    [5, 9]\n",
    "]) \n",
    "\n",
    "# Output y depends ONLY on Study Hours (y = 2 * Study Hours)\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Step 2: Create Lasso Model\n",
    "# We set alpha=0.1. If alpha \n",
    "# is too high, it may zero out important features.)\n",
    "lasso_model = Lasso(alpha=0)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "lasso_model.fit(X, y)\n",
    "single_prediction = lasso_model.predict(np.array([[6, 4]]))\n",
    "print(f\"\\nPrediction for input [6, 4]: {single_prediction[0]}\")\n",
    "# Step 4: Check the Coefficients (The Magic Step)\n",
    "print(f\"Intercept (Bias): {lasso_model.intercept_}\")\n",
    "print(f\"Coefficients (Weights): {lasso_model.coef_}\")\n",
    "\n",
    "# Step 5: Interpretation\n",
    "beta_hours = lasso_model.coef_[0]\n",
    "beta_lucky = lasso_model.coef_[1]\n",
    "print(\"r2_score:\",r2_score(y, lasso_model.predict(X)))\n",
    "print(\"\\n--- CRYSTAL CLEAR RESULTS ---\")\n",
    "print(f\"Importance of Study Hours: {beta_hours:.2f}\")\n",
    "print(f\"Importance of Lucky Number: {beta_lucky:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.0\n",
      "Coefficients: [3. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1336: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:716: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but ElasticNet is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCoefficients: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melastic_model.coef_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Step 5: Predict\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Student studied 6 hours and did 6 assignments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m prediction = \u001b[43melastic_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrediction for (6,6): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_base.py:311\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    298\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1193\u001b[39m, in \u001b[36mElasticNet._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m   1192\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_base.py:290\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    288\u001b[39m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:2923\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2920\u001b[39m     out = X, y\n\u001b[32m   2922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2923\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:2787\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2788\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2789\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 1 features, but ElasticNet is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Step 1: Prepare Data (2 Correlated Features)\n",
    "# Feature 1: Study Hours\n",
    "# Feature 2: Number of Assignments Completed (Usually related to study hours)\n",
    "X = np.array([\n",
    "    [1, 1],   # 1 hour study, 1 assignment\n",
    "    [2, 2],   # 2 hours study, 2 assignments\n",
    "    [3, 3],   # 3 hours study, 3 assignments\n",
    "    [4, 4],   # 4 hours study, 4 assignments\n",
    "    [5, 5]    # 5 hours study, 5 assignments\n",
    "])\n",
    "# Output y = 2 * Study Hours + 1 * Assignments Completed\n",
    "y = np.array([3, 6, 9, 12, 15])  # y = 2x1 + 1x2\n",
    "# Step 2: Create ElasticNet Model\n",
    "# alpha = Total Penalty Strength (Lambda)\n",
    "# l1_ratio = The Mixing Knob (0 to 1)\n",
    "#    - If 1.0 -> It becomes Pure Lasso\n",
    "#    - If 0.0 -> It becomes Pure Ridge\n",
    "#    - If 0.5 -> 50% Lasso + 50% Ridge\n",
    "elastic_model = ElasticNet(alpha=0, l1_ratio=0.2)\n",
    "\n",
    "# Step 3: Train\n",
    "elastic_model.fit(X, y)\n",
    "\n",
    "# Step 4: Check Results\n",
    "print(f\"Intercept: {elastic_model.intercept_}\")\n",
    "print(f\"Coefficients: {elastic_model.coef_}\")\n",
    "\n",
    "# Step 5: Predict\n",
    "# Student studied 6 hours and did 6 assignments\n",
    "prediction = elastic_model.predict([[6]])\n",
    "print(f\"Prediction for (6,6): {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Linear Prediction for 6: 29.00 (Wrong!)\n",
      "\n",
      "Original X:\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "Transformed X (Bias, x, x^2):\n",
      "[[  1.   1.   1.   1.]\n",
      " [  1.   2.   4.   8.]\n",
      " [  1.   3.   9.  27.]\n",
      " [  1.   4.  16.  64.]\n",
      " [  1.   5.  25. 125.]]\n",
      "\n",
      "Polynomial Prediction for 6: 9801.00 (Perfect!)\n",
      "Coefficients: [0.00000000e+00 1.25039949e-15 1.00000000e+00 2.82333451e-16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 1: Create Curved Data (y = x^2)\n",
    "# The relationship is NOT a straight line. It is a curve\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1, 4, 9, 16, 25])\n",
    "\n",
    "# --- SCENARIO A: The Failure (Simple Linear Regression) ---\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X, y)\n",
    "# Predicting for Input 6 (Should be 36)\n",
    "pred_linear = lin_model.predict([[6]])\n",
    "print(f\"Simple Linear Prediction for 6: {pred_linear[0]:.2f} (Wrong!)\")\n",
    "\n",
    "#kinear ki polynomial ki theda enti ante, linear regression straight line fit chesthundi data ki, but polynomial regression curve fit chesthundi data ki. so polynomial regression better ga perform chesthundi curved data lo.\n",
    "# --- SCENARIO B: The Success (Polynomial Regression) ---\n",
    "#polynomial regression formula: y = b0 + b1*x + b2*x^2 + ... + bn*x^n,ex: y = 2 + 3*x + 4*x^2 (here, b0=2, b1=3, b2=4)\n",
    "# Step 2: Transform the Features (The \"Magic\" Step)\n",
    "# We convert single input [x] into multiple inputs [x, x^2]\n",
    "# degree=2 means we want up to power 2.\n",
    "poly = PolynomialFeatures(degree=3)#calculate polynomial features up to degree 1, meaning it will include the bias term and the original feature itself.\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "print(f\"\\nOriginal X:\\n{X}\")\n",
    "print(f\"Transformed X (Bias, x, x^2):\\n{X_poly}\")\n",
    "\n",
    "# Step 3: Train Linear Regression on the NEW Transformed Data\n",
    "# Note: We still use LinearRegression, but on X_poly!\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y)\n",
    "\n",
    "# Step 4: Predict\n",
    "# We must transform the input '6' before predicting!\n",
    "input_val = np.array([[99]])\n",
    "input_val_poly = poly.transform(input_val) # Convert 6 -> [1, 6, 36]\n",
    "pred_poly = poly_model.predict(input_val_poly)\n",
    "\n",
    "print(f\"\\nPolynomial Prediction for 6: {pred_poly[0]:.2f} (Perfect!)\")\n",
    "\n",
    "# Step 5: Check Coefficients\n",
    "print(f\"Coefficients: {poly_model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5656.95s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/likithnaidu/Library/Python/3.11/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/likithnaidu/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/likithnaidu/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.8-cp311-cp311-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-macosx_11_0_arm64.whl (270 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp311-cp311-macosx_10_9_universal2.whl (2.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pillow-12.1.0-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pillow-12.1.0 pyparsing-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- SVR Results ----\n",
      "Input Value: 5.5\n",
      "Predicted Value (Real Scale): 18.63\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Prepare the Data\n",
    "# -------------------------------\n",
    "\n",
    "# Input X: years of experience\n",
    "X_raw = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "\n",
    "# Output y: curved / non-linear relationship (example: salary-like growth)\n",
    "y_raw = np.array([6, 7, 9, 12, 15, 18, 22, 35, 40, 100])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Scaling (CRITICAL for SVR)\n",
    "# -------------------------------\n",
    "# SVR is distance-based, so scaling is mandatory\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale X (already 2D)\n",
    "X_scaled = scaler_X.fit_transform(X_raw)\n",
    "\n",
    "# Scale y (convert to 2D → scale → back to 1D)\n",
    "y_scaled = scaler_y.fit_transform(y_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Create SVR Model\n",
    "# -------------------------------\n",
    "# kernel='rbf' → captures non-linear patterns\n",
    "# C → regularization strength\n",
    "# epsilon → error tolerance tube\n",
    "\n",
    "svr_model = SVR(kernel='rbf', C=10.0, epsilon=0.1)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Train the Model\n",
    "# -------------------------------\n",
    "svr_model.fit(X_scaled, y_scaled)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Prediction\n",
    "# -------------------------------\n",
    "# Predict for a new input value (example: 5.5 years)\n",
    "\n",
    "input_val = np.array([[5.5]])\n",
    "\n",
    "# Scale input\n",
    "input_scaled = scaler_X.transform(input_val)\n",
    "\n",
    "# Predict (scaled output)\n",
    "prediction_scaled = svr_model.predict(input_scaled)\n",
    "\n",
    "# Inverse-scale prediction to real value\n",
    "prediction_real = scaler_y.inverse_transform(\n",
    "    prediction_scaled.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Output\n",
    "# -------------------------------\n",
    "print(\"---- SVR Results ----\")\n",
    "print(f\"Input Value: {input_val[0][0]}\")\n",
    "print(f\"Predicted Value (Real Scale): {prediction_real[0][0]:.2f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Visualization\n",
    "# -------------------------------\n",
    "sns.lineplot(x=X_raw.flatten(), y=y_raw, marker='o', label='Actual Data')\n",
    "plt.scatter(input_val[0][0], prediction_real[0][0], color='red', label='Prediction')\n",
    "plt.xlabel(\"X (Years of Experience)\")\n",
    "plt.ylabel(\"Y (Output)\")\n",
    "plt.title(\"SVR Regression with RBF Kernel\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Master Pipeline ---\n",
      "Training complete.\n",
      "\n",
      "--- Prediction for Input [7.0, NaN] ---\n",
      "Polynomial Pipeline Prediction: 38.95\n",
      "\n",
      "(Info: Internal features created after Polynomial step: 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# --- STEP 1: Create Mixed Data ---\n",
    "# Column 0: Numerical (e.g., Hours Studied) - Has missing value\n",
    "# Column 1: String (e.g., School Type) - Has missing value\n",
    "X_train = np.array([\n",
    "    [5.0, \"Public\"],\n",
    "    [np.nan, \"Private\"], # Missing number\n",
    "    [8.0, \"Public\"],\n",
    "    [2.0, np.nan],       # Missing string\n",
    "    [10.0, \"Private\"]\n",
    "], dtype=object) # dtype=object is needed for mixed numbers/strings\n",
    "\n",
    "# Target: Marks (Curved relationship: more hours = MUCH more marks)\n",
    "y_train = np.array([25, 40, 64, 4, 100])\n",
    "\n",
    "# New data to predict\n",
    "X_new = np.array([[7.0, np.nan]], dtype=object)\n",
    "\n",
    "# --- STEP 2: Define Separate Processes for Numbers and Strings ---\n",
    "\n",
    "# Process for Numerical Column (Index 0)\n",
    "# 1. Fill missing with mean.\n",
    "# 2. Scale it.\n",
    "numerical_transformer = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Process for String Column (Index 1)\n",
    "# 1. Fill missing with a constant value \"Unknown\".\n",
    "# 2. Encode strings to numbers (OneHotEncoder).\n",
    "categorical_transformer = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    # handle_unknown='ignore' prevents errors if new data has brand new strings\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# --- STEP 3: Combine them with ColumnTransformer ---\n",
    "# Tel+Eng: Idi traffic police laga work chestundi.\n",
    "# Column 0 ni numerical pipe ki, Column 1 ni categorical pipe ki pampistundi.\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipe', numerical_transformer, [0]), # Apply to column index 0\n",
    "    ('cat_pipe', categorical_transformer, [1]) # Apply to column index 1\n",
    "])\n",
    "\n",
    "\n",
    "# --- STEP 4: The Final Master Pipeline ---\n",
    "# 1. Preprocess (Clean numbers, clean strings, encode strings).\n",
    "# 2. Generate Polynomial Features (because relationship is curved).\n",
    "# 3. Train Linear Regression on the complex features.\n",
    "master_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_features', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# --- STEP 5: Train and Predict ---\n",
    "print(\"--- Training Master Pipeline ---\")\n",
    "# This single line runs all the complex steps above!\n",
    "master_pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\\n\")\n",
    "\n",
    "print(\"--- Prediction for Input [7.0, NaN] ---\")\n",
    "# The pipeline fills the missing string with \"Unknown\",\n",
    "# encodes it, transforms 7.0 into polynomial features, and predicts.\n",
    "prediction = master_pipeline.predict(X_new)\n",
    "\n",
    "print(f\"Polynomial Pipeline Prediction: {prediction[0]:.2f}\")\n",
    "\n",
    "# Final check of what happened inside (optional)\n",
    "# See how many features went into the final linear model\n",
    "n_features = master_pipeline.named_steps['model'].coef_.shape[0]\n",
    "print(f\"\\n(Info: Internal features created after Polynomial step: {n_features})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Master Pipeline ---\n",
      "Training complete.\n",
      "\n",
      "--- Prediction for Input [7.0, NaN] ---\n",
      "Polynomial Pipeline Prediction: 38.95\n",
      "\n",
      "(Info: Internal features created after Polynomial step: 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# --- STEP 1: Create Mixed Data ---\n",
    "# Column 0: Numerical (e.g., Hours Studied) - Has missing value\n",
    "# Column 1: String (e.g., School Type) - Has missing value\n",
    "X_train = np.array([\n",
    "    [5.0, \"Public\"],\n",
    "    [np.nan, \"Private\"], # Missing number\n",
    "    [8.0, \"Public\"],\n",
    "    [2.0, np.nan],       # Missing string\n",
    "    [10.0, \"Private\"]\n",
    "], dtype=object) # dtype=object is needed for mixed numbers/strings\n",
    "\n",
    "# Target: Marks (Curved relationship: more hours = MUCH more marks)\n",
    "y_train = np.array([25, 40, 64, 4, 100])\n",
    "\n",
    "# New data to predict\n",
    "X_new = np.array([[7.0, np.nan]], dtype=object)\n",
    "\n",
    "# --- STEP 2: Define Separate Processes for Numbers and Strings ---\n",
    "\n",
    "# Process for Numerical Column (Index 0)\n",
    "# 1. Fill missing with mean.\n",
    "# 2. Scale it.\n",
    "numerical_transformer = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "#preprocessor meaning enti ante,ikkada\n",
    "#preprocessor ane object create chesamu,idi different types of data ni process cheyadaniki use avutundi. numerical data ki separate pipeline create chesamu, categorical data ki separate pipeline create chesamu. taruvatha avi combine chesi overall preprocessing ki use chesthundi.\n",
    "# Process for String Column (Index 1)\n",
    "# 1. Fill missing with a constant value \"Unknown\".\n",
    "# 2. Encode strings to numbers (OneHotEncoder).\n",
    "categorical_transformer = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    # handle_unknown='ignore' prevents errors if new data has brand new strings\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))#it'll convert categorical string data into a numeric format that machine learning models can understand.\n",
    "])\n",
    "\n",
    "# --- STEP 3: Combine them with ColumnTransformer ---\n",
    "# Tel+Eng: Idi traffic police laga work chestundi.\n",
    "# Column 0 ni numerical pipe ki, Column 1 ni categorical pipe ki pampistundi.\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipe', numerical_transformer, [0]), # Apply to column index 0\n",
    "    ('cat_pipe', categorical_transformer, [1]) # Apply to column index 1\n",
    "])\n",
    "#already onehotencoder undhi kadha,malli endhuku Columntransformer use chesamu ante,\n",
    "#onehotencoder categorical data ni numeric format lo convert chesthundi. kani ikkada mixed data undhi, numerical and categorical. so ColumnTransformer use chesi, numerical data ki separate processing apply cheyachu, categorical data ki separate processing apply cheyachu. so overall mixed data ni handle cheyadaniki ColumnTransformer use chesamu.\n",
    "\n",
    "# --- STEP 4: The Final Master Pipeline ---\n",
    "# 1. Preprocess (Clean numbers, clean strings, encode strings).\n",
    "# 2. Generate Polynomial Features (because relationship is curved).\n",
    "# 3. Train Linear Regression on the complex features.\n",
    "master_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_features', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# --- STEP 5: Train and Predict ---\n",
    "print(\"--- Training Master Pipeline ---\")\n",
    "# This single line runs all the complex steps above!\n",
    "master_pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\\n\")\n",
    "\n",
    "print(\"--- Prediction for Input [7.0, NaN] ---\")\n",
    "# The pipeline fills the missing string with \"Unknown\",\n",
    "# encodes it, transforms 7.0 into polynomial features, and predicts.\n",
    "prediction = master_pipeline.predict(X_new)\n",
    "\n",
    "print(f\"Polynomial Pipeline Prediction: {prediction[0]:.2f}\")\n",
    "\n",
    "# Final check of what happened inside (optional)\n",
    "# See how many features went into the final linear model\n",
    "n_features = master_pipeline.named_steps['model'].coef_.shape[0]\n",
    "print(f\"\\n(Info: Internal features created after Polynomial step: {n_features})\")\n",
    "#overall data(input/output) meaning enti ante,\n",
    "#mixed data ni handle cheyadaniki pipeline create chesamu. numerical data lo missing values ni mean tho fill chesamu, categorical data lo missing values ni \"Unknown\" tho fill chesamu. taruvatha categorical data ni one-hot encoding tho numeric format lo convert chesamu. ipudu polynomial features generate chesi linear regression model train chesamu. finally new input ki prediction chesamu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# --- STEP 1: Create Data ---\n",
    "# X: Hours Studied\n",
    "# y: Marks Obtained\n",
    "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
    "y = np.array([10, 20, 30, 80, 85, 90])\n",
    "# Notice the Jump: From 3 to 4 hours, marks jump from 30 to 80!\n",
    "# A Decision Tree loves these sudden jumps.\n",
    "\n",
    "# --- STEP 2: Create Model ---\n",
    "# max_depth=2: We tell the tree \"Don't grow too big\".\n",
    "# Just ask 2 levels of questions. (Simple & Clean)\n",
    "tree_model = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "# --- STEP 3: Train ---\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# --- STEP 4: Prediction ---\n",
    "# Let's predict for 3.5 hours (Between 3 and 4)\n",
    "prediction = tree_model.predict([[3.5]])\n",
    "print(f\"Prediction for 3.5 hours: {prediction[0]}\")\n",
    "\n",
    "\n",
    "# --- STEP 5: VISUALIZATION (The Magic) ---\n",
    "\n",
    "# A. Visualizing the Tree Structure (Flowchart)\n",
    "plt.figure(figsize=(10, 6)) # Create a big empty picture\n",
    "plot_tree(tree_model, \n",
    "          feature_names=['Hours'], \n",
    "          filled=True, \n",
    "          rounded=True)\n",
    "plt.title(\"How the Machine Thinks (The Decision Tree)\")\n",
    "plt.show()\n",
    "\n",
    "# B. Visualizing the Prediction Line\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, color='red', label='Actual Data') # The red dots\n",
    "\n",
    "# To see the \"Steps\", we need a smooth range of inputs\n",
    "X_grid = np.arange(0, 7, 0.01).reshape(-1, 1) # 0.0, 0.01, 0.02...\n",
    "plt.plot(X_grid, tree_model.predict(X_grid), color='blue', label='Tree Prediction')\n",
    "\n",
    "plt.title(\"Decision Tree Regression (Step-like Prediction)\")\n",
    "plt.xlabel(\"Hours Studied\")\n",
    "plt.ylabel(\"Marks\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --- STEP 1: Create Complex Curved Data (Sine Wave) ---\n",
    "# We use a Sine wave because it is curvy. \n",
    "# A single tree would fail here (it would make big blocky steps).\n",
    "X = np.arange(0, 10, 0.1).reshape(-1, 1) # 0.0 to 9.9\n",
    "y = np.sin(X).ravel() # A perfect wave\n",
    "\n",
    "# Let's add some \"Noise\" (Random mistakes) to make it realistic\n",
    "# Real life data is never perfect.\n",
    "y_noisy = y + np.random.normal(0, 0.1, y.shape)\n",
    "\n",
    "# --- STEP 2: Create Random Forest Model ---\n",
    "# n_estimators=100: We build 100 Trees!\n",
    "# The final result is the AVERAGE of these 100 trees.\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y_noisy)\n",
    "\n",
    "# --- STEP 3: Create XGBoost Model ---\n",
    "# n_estimators=100: It also builds 100 trees.\n",
    "# learning_rate=0.1: It corrects mistakes slowly and carefully.\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X, y_noisy)\n",
    "\n",
    "# --- STEP 4: Predictions ---\n",
    "rf_pred = rf_model.predict(X)\n",
    "xgb_pred = xgb_model.predict(X)\n",
    "\n",
    "# --- STEP 5: VISUALIZATION ( The Showdown ) ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 1. Plot Actual Data\n",
    "plt.scatter(X, y_noisy, color='black', label='Noisy Data', s=10)\n",
    "\n",
    "# 2. Plot Random Forest (Green)\n",
    "plt.plot(X, rf_pred, color='green', linewidth=2, label='Random Forest (Smooth Steps)')\n",
    "\n",
    "# 3. Plot XGBoost (Red)\n",
    "plt.plot(X, xgb_pred, color='red', linestyle='--', linewidth=2, label='XGBoost (Sharp Fit)')\n",
    "\n",
    "plt.title(\"The Battle: Random Forest vs XGBoost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "R² Score: -0.7104\n",
      "Mean Squared Error: 4276000000.00\n",
      "\n",
      "Predicted Price for House (Size=3200 sqft, Age=18 years): $3245803.52\n",
      "THE METRIC FOR LINEAR-POLYNOMIAL REGRESSION IS R2_SCORE AND MEAN SQUARED ERROR\n",
      "HIGH R2_SCORE AND LOW MEAN SQUARED ERROR INDICATE A GOOD FIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# --- 1. CREATE DATASET (The Ingredients) ---\n",
    "# Scenario: Predicting House Price based on Size and Age\n",
    "# Logic: Size increases price (Linear), Age decreases price but curves (Polynomial)\n",
    "data = {\n",
    "    'Size': [1000, 1500, 2000, 2500, 3000, 3500, 4000],\n",
    "    'Age':  [5, 10, 15, 20, 25, 30, 35],\n",
    "    'Price': [200000, 300000, 380000, 450000, 500000, 480000, 450000] \n",
    "    # Notice Price drops after age 25 (Curve!)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[['Size', 'Age']]\n",
    "y = df['Price']\n",
    "\n",
    "# Split Data (80% Training, 20% Testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model=make_pipeline(\n",
    "    PolynomialFeatures(degree=2),\n",
    "    LinearRegression()\n",
    ")\n",
    "# --- 2. TRAIN THE MODEL (Cooking) ---\n",
    "model.fit(X_train, y_train)\n",
    "# --- 3. EVALUATE THE MODEL (Tasting) ---\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "# --- 4. MAKE A PREDICTION (Serving) ---\n",
    "new_house = np.array([[3200, 18]])  # Size=3200 sqft, Age=18 years\n",
    "predicted_price = model.predict(new_house)\n",
    "print(f\"\\nPredicted Price for House (Size=3200 sqft, Age=18 years): ${predicted_price[0]:.2f}\")\n",
    "print(\"THE METRIC FOR LINEAR-POLYNOMIAL REGRESSION IS R2_SCORE AND MEAN SQUARED ERROR\")\n",
    "print(\"HIGH R2_SCORE AND LOW MEAN SQUARED ERROR INDICATE A GOOD FIT\")\n",
    "print(\"POLYNOMIAL FEATURES HELP CAPTURE NON-LINEAR RELATIONSHIPS IN DATA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/likithnaidu/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/likithnaidu/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m684.9 kB/s\u001b[0m  \u001b[33m0:00:15\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
