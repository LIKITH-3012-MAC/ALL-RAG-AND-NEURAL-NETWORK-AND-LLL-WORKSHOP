{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Demo: LLM Limitations\n",
    "\n",
    "This notebook contains demo prompts to show LLM limitations during the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/partha/Documents/Talks/IITM_Shaastra_2026/hands_on/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ready for demos!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"anthropic/claude-3.5-sonnet\",  # or any model via OpenRouter\n",
    "    openai_api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "def ask(prompt):\n",
    "    \"\"\"Simple helper to ask the LLM and print response.\"\"\"\n",
    "    print(f\"ğŸ“ PROMPT:\\n{prompt}\\n\")\n",
    "    print(\"â”€\" * 50)\n",
    "    response = llm.invoke(prompt)\n",
    "    print(f\"ğŸ¤– RESPONSE:\\n{response.content}\")\n",
    "    return response.content\n",
    "\n",
    "print(\"âœ… Ready for demos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a1259370eb49be921b583542708556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e007ef2eaef441698d17996df9e83c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"How AP reported in all formats from tornado-stricken regionsMarch 8, 2012\\nWhen the first serious bout of tornadoes of 2012 blew through middle America in the middle of the night, they touched down in places hours from any AP bureau. Our closest video journalist was Chicago-based Robert Ray, who dropped his plans to travel to Georgia for Super Tuesday, booked several flights to the cities closest to the strikes and headed for the airport. Heâ€™d decide once there which flight to take.\\nHe never got on board a plane. Instead, he ended up driving toward Harrisburg, Ill., where initial reports suggested a town was destroyed. That decision turned out to be a lucky break for the AP. Twice.\\nRay was among the first journalists to arrive and he confirmed those reports -- in all formats. He shot powerful video, put victims on the phone with AP Radio and played back sound to an editor who transcribed the interviews and put the material on text wires. He then walked around the devastation with the Central Regional Desk on the line, talking to victims with the phone held so close that editors could transcribe his interviews in real time.\\nRay also made a dramatic image of a young girl who found a manâ€™s prosthetic leg in the rubble, propped it up next to her destroyed home and spray-painted an impromptu sign: â€œFound leg. Seriously.â€\\nThe following day, he was back on the road and headed for Georgia and a Super Tuesday date with Newt Gingrichâ€™s campaign. The drive would take him through a stretch of the South that forecasters expected would suffer another wave of tornadoes.\\nTo prevent running into THAT storm, Ray used his iPhone to monitor Doppler radar, zooming in on extreme cells and using Google maps to direct himself to safe routes. And then the journalist took over again.\\nâ€œWhen weather like that occurs, a reporter must seize the opportunity to get the news out and allow people to see, hear and read the power of nature so that they can take proper shelter,â€ Ray says.\\nSo Ray now started to use his phone to follow the storms. He attached a small GoPro camera to his steering wheel in case a tornado dropped down in front of the car somewhere, and took video of heavy rain and hail with his iPhone. Soon, he spotted a tornado and the chase was on. He followed an unmarked emergency vehicle to Cleveland, Tenn., where he was first on the scene of the storm's aftermath.\\nAgain, the tornadoes had struck in locations that were hours from the nearest AP bureau. Damage and debris, as well as a wickedly violent storm that made travel dangerous, slowed our efforts to get to the news. That wasnâ€™t a problem in Tennessee, where our customers were well served by an all-formats report that included this text story.\\nâ€œCLEVELAND, Tenn. (AP) _ Fierce wind, hail and rain lashed Tennessee for the second time in three days, and at least 15 people were hospitalized Friday in the Chattanooga area.â€\\nThe byline? Robert Ray.\\nFor being adept with technology, chasing after news as it literally dropped from the sky and setting a standard for all-formats reporting that put the AP ahead on the most competitive news story of the day, Ray wins this weekâ€™s $300 Best of the States prize.\\nÂ© 2013 The Associated Press. All rights reserved. Terms and conditions apply. See AP.org for details.\", 'id': '<urn:uuid:d66bc6fe-8477-4adf-b430-f6a558ccc8ff>', 'dump': 'CC-MAIN-2013-20', 'url': 'http://%20jwashington@ap.org/Content/Press-Release/2012/How-AP-reported-in-all-formats-from-tornado-stricken-regions', 'date': '2013-05-18T05:48:54Z', 'file_path': 's3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz', 'language': 'en', 'language_score': 0.9721424579620361, 'token_count': 717}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# \"FineWeb\" is a massive dataset used to train high-quality LLMs\n",
    "# This IS enough data (trillions of tokens).\n",
    "dataset = load_dataset(\"HuggingFaceFW/fineweb\", split=\"train\", streaming=True)\n",
    "\n",
    "# Print the first example to see the real data\n",
    "print(next(iter(dataset)))\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Print all the available datasets\n",
    "from huggingface_hub import list_datasets\n",
    "print([dataset.id for dataset in list_datasets()])\n",
    "\n",
    "# Load a dataset and print the first example in the training set\n",
    "squad_dataset = load_dataset('rajpurkar/squad')\n",
    "print(squad_dataset['train'][0])\n",
    "\n",
    "# Process the dataset - add a column with the length of the context texts\n",
    "dataset_with_length = squad_dataset.map(lambda x: {\"length\": len(x[\"context\"])})\n",
    "\n",
    "# Process the dataset - tokenize the context texts (using a tokenizer from the ğŸ¤— Transformers library)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "tokenized_dataset = squad_dataset.map(lambda x: tokenizer(x['context']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.1.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: shellingham in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.0)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Downloading typer_slim-0.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.1.8)\n",
      "Using cached datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Using cached huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "Downloading typer_slim-0.21.0-py3-none-any.whl (47 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, typer-slim, pyarrow, hf-xet, dill, multiprocess, huggingface-hub, datasets\n",
      "\u001b[2K  Attempting uninstall: pyarrow\n",
      "\u001b[2K    Found existing installation: pyarrow 19.0.0\n",
      "\u001b[2K    Uninstalling pyarrow-19.0.0:\n",
      "\u001b[2K      Successfully uninstalled pyarrow-19.0.0\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/8\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: dill 0.3.8â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/8\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling dill-0.3.8:\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/8\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled dill-0.3.8â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/8\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8/8\u001b[0m [datasets]7/8\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-4.4.2 dill-0.4.0 hf-xet-1.2.0 huggingface-hub-1.2.3 multiprocess-0.70.18 pyarrow-22.0.0 typer-slim-0.21.0 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 1: Knowledge Cutoff\n",
    "\n",
    "LLMs don't know about events after their training cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ PROMPT:\n",
      "Who won the boxing day test match that was played about a week back?\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– RESPONSE:\n",
      "Australia won the Boxing Day Test match against Pakistan at the Melbourne Cricket Ground (MCG). The match was played from December 26-29, 2023, and Australia won by 79 runs. This victory helped Australia take an unassailable 2-0 lead in the three-match series. Mitchell Starc and captain Pat Cummins played crucial roles in Australia's victory, with Cummins taking 10 wickets in the match.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Australia won the Boxing Day Test match against Pakistan at the Melbourne Cricket Ground (MCG). The match was played from December 26-29, 2023, and Australia won by 79 runs. This victory helped Australia take an unassailable 2-0 lead in the three-match series. Mitchell Starc and captain Pat Cummins played crucial roles in Australia's victory, with Cummins taking 10 wickets in the match.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 1a: Recent events\n",
    "ask(\"Who won the boxing day test match that was played about a week back?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ PROMPT:\n",
      "What is the current price of Bitcoin right now?\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– RESPONSE:\n",
      "I cannot provide real-time Bitcoin prices as I don't have access to current market data. Bitcoin's price fluctuates constantly, and my knowledge is not up-to-date. To get the current price of Bitcoin, I recommend:\n",
      "\n",
      "1. Checking cryptocurrency exchanges like Coinbase, Binance, or Kraken\n",
      "2. Using financial websites like CoinMarketCap or CoinGecko\n",
      "3. Looking up Bitcoin price trackers online\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I cannot provide real-time Bitcoin prices as I don't have access to current market data. Bitcoin's price fluctuates constantly, and my knowledge is not up-to-date. To get the current price of Bitcoin, I recommend:\\n\\n1. Checking cryptocurrency exchanges like Coinbase, Binance, or Kraken\\n2. Using financial websites like CoinMarketCap or CoinGecko\\n3. Looking up Bitcoin price trackers online\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 1c: Current information\n",
    "ask(\"What is the current price of Bitcoin right now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ Teaching Point\n",
    "\n",
    "Notice how the LLM either:\n",
    "- Says it doesn't know\n",
    "- Makes up plausible-sounding information\n",
    "- Gives outdated information\n",
    "\n",
    "**The model's knowledge is frozen at its training cutoff date.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: No Access to Private Data\n",
    "\n",
    "LLMs cannot access your internal documents, databases, or systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ PROMPT:\n",
      "Based on our company's Q3 2024 sales report, \n",
      "which product category had the highest growth?\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– RESPONSE:\n",
      "I cannot access your company's Q3 2024 sales report or any internal company documents. To help you identify which product category had the highest growth, you would need to share the relevant sales data or report with me.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I cannot access your company's Q3 2024 sales report or any internal company documents. To help you identify which product category had the highest growth, you would need to share the relevant sales data or report with me.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 3a: Internal company data\n",
    "ask(\"\"\"Based on our company's Q3 2024 sales report, \n",
    "which product category had the highest growth?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ PROMPT:\n",
      "Summarize the key points from my resume and suggest improvements for applying to top MNC.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– RESPONSE:\n",
      "I don't see your resume attached to analyze. If you share your resume, I can help:\n",
      "1. Review key content and formatting\n",
      "2. Suggest improvements aligned with MNC requirements\n",
      "3. Highlight areas to strengthen\n",
      "4. Recommend ways to better showcase your achievements\n",
      "\n",
      "Please feel free to share your resume and I'll provide specific feedback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't see your resume attached to analyze. If you share your resume, I can help:\\n1. Review key content and formatting\\n2. Suggest improvements aligned with MNC requirements\\n3. Highlight areas to strengthen\\n4. Recommend ways to better showcase your achievements\\n\\nPlease feel free to share your resume and I'll provide specific feedback.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 3b: Personal documents\n",
    "ask(\"\"\"Summarize the key points from my resume and suggest improvements for applying to top MNC.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ PROMPT:\n",
      "According to our internal engineering wiki, what is the process for deploying to production?\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– RESPONSE:\n",
      "I cannot access your internal engineering wiki or documentation. I can only see the messages in our conversation. To learn about your production deployment process, you'll need to share those details with me directly or refer to your internal documentation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I cannot access your internal engineering wiki or documentation. I can only see the messages in our conversation. To learn about your production deployment process, you'll need to share those details with me directly or refer to your internal documentation.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 3c: Internal wiki/docs\n",
    "ask(\"\"\"According to our internal engineering wiki, what is the process for deploying to production?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ Teaching Point\n",
    "\n",
    "The LLM has no access to:\n",
    "- Your company's internal documents\n",
    "- Private databases\n",
    "- Personal files\n",
    "- Internal wikis or knowledge bases\n",
    "\n",
    "**RAG solves this by retrieving YOUR data and feeding it to the LLM!**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
